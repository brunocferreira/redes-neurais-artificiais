{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especialização em Inteligência Artificial\n",
    "# Trabalho de Redes Neurais e Aprendizagem Profunda\n",
    "\n",
    "Alunos: *Bruno da Cunha Ferreira* (1, 2, 3, 4 e 9) e Alexandre Fortes Santana (5, 6, 7, 8)\n",
    "\n",
    "Professor: **Agnaldo José da Rocha Reis - UFOP** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. O que é inteligência para você?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É exercer o pensamento: elaborar algo em sua mente, analisar isso, tomar ou não decisões, continuar ou não em um caminho, ter a capacidade de encontrar soluções, de construir provisões, de melhorar um recurso ou habilidades, de superar desafios ou de se manter onde está... independente, de excercer o livre arbítrio e a liberdade de escolha."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Em sua opinião, o que aconteceria se alguém descobrisse como implementar uma IA mais abrangente (e.g., AGI) em um robô?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso alguem descubra, espero que não implemente. Porque um robô inteligente poderia ter habilidades \"paranormais\" comparados aos seres humanos, como a \"telepatia\" com os seus semelhantes, ao poder usar e acessar qualquer coisa que esteja conectado com a internet, fazer múltiplas tarefas ao mesmo tempo. Aliás, os robôs poderiam reagrupar e remanejar os dados em suas \"mentes\" (BigData Centers) para atender suas necessidades de previsões mais complexas ou de trabalhos sincronizados a nível global. Isso pode ser de grande ajuda para os seres humanos se ele, em sua inteligência, não tiver vontade de se perpetuar vivo ou de garantir a sobrevivência da sua espécie, se assim ele o definir, entretanto, seria um caos total devido ao tamanho da rede de acesso dele e a velocidade na qual ele conseguiria coordenar ataques aos seres humanos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A partir da análise de um processo de destilação fracionada de petróleo observou-se que determinado óleo poderia ser classificado em duas classes de pureza {C1 e C2}, mediante a medição de três grandezas {x1 , x2 e x3} que representam algumas das propriedades físico-químicas do óleo. Para tanto, pretende-se utilizar um perceptron para executar a classificação automática dessas duas classes. Assim, baseadas nas informações coletadas do processo, formou-se o conjunto de treinamento em anexo1 , tomando por convenção o valor –1 para óleo pertencente à classe C1 e o valor +1 para óleo pertencente à classe C2.\n",
    "\n",
    "### Daí, pede-se:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Execute dois treinamentos para a rede perceptron, inicializando-se o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função para treinar o perceptron\n",
    "def treinamento_perceptron(X, y, taxa_aprendizado=0.001, n_iteracoes=1000, tolerancia=1e-3):\n",
    "    \"\"\"\n",
    "    Esta função é usada para treinar o modelo Perceptron.\n",
    "\n",
    "    Parâmetros:\n",
    "    - ``X`` (numpy.ndarray): Uma matriz bidimensional representando os dados de entrada (features). \n",
    "                       Cada sublista representa uma amostra de dados.\n",
    "    - ``y`` (numpy.ndarray): Uma lista unidimensional representando os rótulos de classe correspondentes a cada amostra em X.\n",
    "    - ``taxa_aprendizado`` (float): Um número de ponto flutuante representando a taxa de aprendizado para o algoritmo de treinamento. \n",
    "                              O valor padrão é 0.001.\n",
    "    - ``n_iteracoes`` (int): Um número inteiro representando o número de iterações para o algoritmo de treinamento. \n",
    "                       O valor padrão é 1000.\n",
    "    - ``tolerancia`` (float): Um número de ponto flutuante representando a tolerância para a mudança nos pesos entre as épocas. \n",
    "                       O valor padrão é -0.001.\n",
    "\n",
    "    Retorno:\n",
    "    - ``pesos`` (numpy.ndarray): Uma lista de números de ponto flutuante representando os pesos aprendidos para cada feature.\n",
    "    - ``vies`` (float): Um número de ponto flutuante representando o vies aprendido.\n",
    "    \n",
    "    Exemplo:\n",
    "    >>> X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    >>> y = np.array([0, 0, 0, 1])\n",
    "    >>> treinamento_perceptron(X, y)\n",
    "    (array([0.51423444, 0.55905198]), 0.02)\n",
    "    \"\"\"\n",
    "    # Obtem o número de amostras e características\n",
    "    n_amostras, n_features = X.shape\n",
    "\n",
    "    # Inicializa os pesos e o vies com valores aleatórios\n",
    "    pesos = np.random.rand(n_features)\n",
    "    vies = 0\n",
    "\n",
    "    # Imprime os pesos iniciais\n",
    "    print(f'Pesos iniciais: {pesos}')\n",
    "\n",
    "    # Transforma os rótulos y em 1 e -1\n",
    "    y_ = np.array([1 if i > 0 else -1 for i in y])\n",
    "\n",
    "    teste = 1000\n",
    "    # Loop para o número de iterações\n",
    "    for epoch in range(n_iteracoes):\n",
    "        # Guarda os pesos da época anterior\n",
    "        pesos_anteriores = pesos.copy()\n",
    "        \n",
    "        # Loop para cada amostra em X\n",
    "        for idx, x_i in enumerate(X):\n",
    "            # Calcula a condição se o rótulo real é maior que a previsão\n",
    "            condicao = y_[idx] - predict_perceptron(x_i, pesos, vies)\n",
    "            # Se a condição for maior ou igual a zero, define a condição como 1, senão define como -1\n",
    "            if condicao >= 0:\n",
    "                condicao = 1\n",
    "            else:\n",
    "                condicao = -1\n",
    "            # Calcula os novos pesos e vies\n",
    "            novos_pesos = pesos + taxa_aprendizado * (condicao - predict_perceptron(x_i, pesos, vies)) * x_i\n",
    "            novo_vies = vies + taxa_aprendizado * (condicao - predict_perceptron(x_i, pesos, vies))\n",
    "\n",
    "            # Verifica a condição de parada\n",
    "            if np.sqrt(np.sum((novos_pesos - pesos_anteriores) ** 2)) < tolerancia:\n",
    "                # Imprime os resultados\n",
    "                print(f'O treinamento convergiu após {epoch} épocas.')\n",
    "                print(f'Pesos finais: {novos_pesos}')\n",
    "                print(f'Vies final: {novo_vies}')\n",
    "                return novos_pesos, novo_vies\n",
    "\n",
    "            # Atualiza os pesos e o vies\n",
    "            pesos = novos_pesos\n",
    "            vies = novo_vies\n",
    "\n",
    "    # Retorna os pesos e o vies\n",
    "    print(f'O treinamento não convergiu após {n_iteracoes} épocas.')\n",
    "    return pesos, vies\n",
    "\n",
    "# Função para fazer previsões com o perceptron\n",
    "def predict_perceptron(X, pesos, vies):\n",
    "    \"\"\"\n",
    "    Esta função é usada para fazer previsões com o modelo Perceptron.\n",
    "\n",
    "    Parâmetros:\n",
    "    - ``X`` (numpy.ndarray): Uma matriz bidimensional representando os dados de entrada (features). \n",
    "                       Cada sublista representa uma amostra de dados.\n",
    "    - ``pesos`` (numpy.ndarray): Uma lista de números de ponto flutuante representando os pesos do modelo Perceptron. \n",
    "                           Estes são os pesos que foram aprendidos durante o treinamento.\n",
    "    - ``vies`` (float): Um número de ponto flutuante representando o vies do modelo Perceptron. \n",
    "                  Este é o vies que foi aprendido durante o treinamento.\n",
    "\n",
    "    Retorno:\n",
    "    - ``numpy.ndarray``: Uma lista de previsões. Cada previsão é 1 se a soma linear for maior ou igual a zero, caso contrário é -1.\n",
    "    \n",
    "    Exemplo:\n",
    "    >>> X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    >>> pesos = np.array([0.51423444, 0.55905198])\n",
    "    >>> vies = 0.02\n",
    "    >>> predict_perceptron(X, pesos, vies)\n",
    "    array([1, 1, 1, 1])\n",
    "    \"\"\"\n",
    "    # Calcula a soma linear\n",
    "    soma_linear = np.dot(X, pesos) + vies\n",
    "    # Se a soma linear for maior ou igual a zero, retorna 1, senão retorna -1\n",
    "    return np.where(soma_linear>=0, 1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1        2    3\n",
      "0 -0.6508  0.1097   4.0009 -1.0\n",
      "1 -1.4492  0.8896   4.4005 -1.0\n",
      "2  2.0850  0.6876  12.0710 -1.0\n",
      "3  0.2626  1.1476   7.7985  1.0\n",
      "4  0.6418  1.0234   7.0427  1.0\n",
      "Pesos iniciais: [0.78353852 0.57983661 0.46796825]\n",
      "O treinamento convergiu após 127 épocas.\n",
      "Pesos finais: [ 0.2487249   0.20217819 -0.20651529]\n",
      "Vies final: -0.10400000000000004\n",
      "Pesos iniciais: [0.36694959 0.05955781 0.14902218]\n",
      "O treinamento convergiu após 37 épocas.\n",
      "Pesos finais: [ 0.13230839  0.05741267 -0.08027671]\n",
      "Vies final: -0.04000000000000001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Carrega os dados do arquivo .dat para um DataFrame\n",
    "dados1 = pd.read_csv('./data/tab_treinamento1.dat', sep='\\s+', header=None)\n",
    "\n",
    "# Imprimindo as primeiras linhas do DataFrame\n",
    "print(dados1.head())\n",
    "\n",
    "# Adiciona nomes às colunas\n",
    "dados1.columns = ['x1', 'x2', 'x3', 'c']\n",
    "\n",
    "# Separa as features e os rótulos\n",
    "X1 = dados1.iloc[:, :-1].values\n",
    "y1 = dados1.iloc[:, -1].values\n",
    "\n",
    "# Pré-processamento de dados\n",
    "# Normalização\n",
    "scaler = MinMaxScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "\n",
    "# Divisão de dados\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tratamento de dados ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X1_train = imputer.fit_transform(X1_train)\n",
    "X1_test = imputer.transform(X1_test)\n",
    "\n",
    "# Treina o perceptron\n",
    "pesos1, vies1 = treinamento_perceptron(X1_train, y1_train)\n",
    "pesos2, vies2 = treinamento_perceptron(X1_train, y1_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o treinamento do nosso *perceptron* conforme solicitado pelo enunciado, obtivemos o seguinte resultado em b:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Registre os resultados dos dois treinamentos na tabela a seguir:\n",
    "\n",
    "| Treinamento | Vetor de Pesos Inicial </br> b \\ w1 \\ w2 \\ w3 |  Vetor de Pesos Final </br> b \\ w1 \\ w2 \\ w3 | Número de Épocas |\n",
    "|-------------|-----------------------------------------------|----------------------------------------------|------------------|\n",
    "| 1º (T1)     | 0 \\ 0.78353852 \\ 0.57983661 \\ 0.46796825    | -0.10400000000000004 \\ 0.2487249 \\ 0.20217819 \\ -0.20651529 | 127 |\n",
    "| 2º (T2)     | 0 \\ 0.36694959 \\ 0.05955781 \\ 0.14902218    | -0.04000000000000001 \\ 0.13230839 \\ 0.05741267 \\ -0.08027671 | 37 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Após o treinamento do perceptron, aplique-o na classificação automática de novas amostras de óleo (ver arquivo tab_teste1.dat), indicando-se na tabela seguinte os resultados das saídas (Classes) referentes aos dois processos de treinamento realizados no item a.\n",
    "###### 1 tab_treinamento1.\n",
    "\n",
    "| Amostra | x1 | x2 | x3 | y </br> (T1) | y </br> (T2) |\n",
    "|---------|----|----|----|--------------|--------------|\n",
    "| 1 | -0.3565 | 0.0620 | 5.9891 |           |              |\n",
    "| 2 | -0.7842 | 1.1267 | 5.5912 |           |              |\n",
    "| 3 | 0.3012 | 0.5611 | 5.8234 |            |              |\n",
    "| 4 | 0.7757 | 1.0648 | 8.0677 |            |              |\n",
    "| 5 | 0.1570 | 0.8028 | 6.3040 |            |              |\n",
    "| 6 | -0.7014 | 1.0316 | 3.6005 |           |              |\n",
    "| 7 | 0.3748 | 0.1536 | 6.1537 |            |              |\n",
    "| 8 | -0.6920 | 0.9404 | 4.4058 |           |              |\n",
    "| 9 | -1.3970 | 0.7141 | 4.9263 |           |              |\n",
    "| 10 | -1.8842 | -0.2805 | 1.2548 |           |              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_novos_dados(pesos, vies):\n",
    "    \"\"\"\n",
    "    Esta função carrega um conjunto de dados do arquivo tab_teste1.dat, realiza o pré-processamento desses dados e faz previsões usando um perceptron treinado.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - ``pesos`` (array): O array de pesos do perceptron treinado.\n",
    "    - ``vies`` (float): O viés do perceptron treinado.\n",
    "    \n",
    "    Retorno:\n",
    "    - ``None``. A função imprime os valores preditos para o novo conjunto de dados.\n",
    "    \n",
    "    Exemplo:\n",
    "    >>> prever_novos_dados(pesos1, vies1)\n",
    "    Valores preditos, dado os pesos ([0.5, 0.6, 0.7]) e o bias (0.1): ['C1', 'C2', 'C1', 'C2']\n",
    "    \"\"\"\n",
    "    # Carrega os novos dados do arquivo .dat para um DataFrame\n",
    "    dados_novos = pd.read_csv('./data/tab_teste1.dat', sep='\\s+', header=None)\n",
    "\n",
    "    # Adiciona nomes às colunas\n",
    "    dados_novos.columns = ['x1', 'x2', 'x3']\n",
    "\n",
    "    # Separa as features\n",
    "    X_novos = dados_novos.values\n",
    "\n",
    "    # Pré-processamento de dados\n",
    "    # Normalização\n",
    "    X_novos = scaler.transform(X_novos)\n",
    "\n",
    "    # Tratamento de dados ausentes\n",
    "    X_novos = imputer.transform(X_novos)\n",
    "\n",
    "    # Faz as previsões com os pesos e vies aprendidos\n",
    "    y_pred = predict_perceptron(X_novos, pesos, vies)\n",
    "\n",
    "    # Converte os valores de y_pred para 'C1' se for -1 e 'C2' se for positivo\n",
    "    y_pred = np.where(y_pred == -1, 'C1', 'C2')\n",
    "\n",
    "    # Imprime os valores preditos\n",
    "    print(f'Valores preditos, dado os pesos ({pesos}) e o bias ({vies}):', y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores preditos, dado os pesos ([ 0.2487249   0.20217819 -0.20651529]) e o bias (-0.10400000000000004): ['C1' 'C2' 'C2' 'C2' 'C2' 'C2' 'C1' 'C2' 'C1' 'C1']\n",
      "Valores preditos, dado os pesos ([ 0.13230839  0.05741267 -0.08027671]) e o bias (-0.04000000000000001): ['C1' 'C2' 'C2' 'C2' 'C2' 'C2' 'C2' 'C2' 'C1' 'C1']\n"
     ]
    }
   ],
   "source": [
    "prever_novos_dados(pesos1, vies1)\n",
    "prever_novos_dados(pesos2, vies2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo a predição do perceptron treinado, obtivemos o seguinte resultado classificatório para os dados de tab_teste1.dat:\n",
    "\n",
    "| Amostra | x1 | x2 | x3 | y </br> (T1) | y </br> (T2) |\n",
    "|---------|----|----|----|--------------|--------------|\n",
    "| 1 | -0.3565 | 0.0620 | 5.9891 | C1 | C1 |\n",
    "| 2 | -0.7842 | 1.1267 | 5.5912 | C2 | C2 |\n",
    "| 3 | 0.3012 | 0.5611 | 5.8234 | C2 | C2 |\n",
    "| 4 | 0.7757 | 1.0648 | 8.0677 | C2 | C2 |\n",
    "| 5 | 0.1570 | 0.8028 | 6.3040 | C2 | C2 |\n",
    "| 6 | -0.7014 | 1.0316 | 3.6005 | C2 | C2 |\n",
    "| 7 | 0.3748 | 0.1536 | 6.1537 | C1 | C2 |\n",
    "| 8 | -0.6920 | 0.9404 | 4.4058 | C2 | C2 |\n",
    "| 9 | -1.3970 | 0.7141 | 4.9263 | C1 | C1 |\n",
    "| 10 | -1.8842 | -0.2805 | 1.2548 | C1 | C1 |\n",
    "\n",
    "###### **Referências**: C1 -> -1 e C2 -> +1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Explique por que o número de épocas de treinamento varia a cada vez que se executa o treinamento do perceptron."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro: porque os pesos iniciais são aleatórios, deixando-os próximos ou distantes do melhor peso para o modelo; segundo: porque a taxa de aprendizado é pequena, mas não tão pequena a ponto do algorítmo não encontrar o ponto de convergência, ou seja, ela está ideal para o algorítmo não realizar alterações muitos significativas nos pesos e no deslocamento do bias no hiperplano dos dados para encontrar o melhor modelo na época em que não houver uma mudança significativa (menor que a tolerância) dos pesos e do vies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Qual é a principal limitação do perceptron quando aplicado em problemas de classificação de padrões?\n",
    "\n",
    "##### ANEXO – Conjunto de Treinamento (ver arquivo tab_treinamento1.dat).\n",
    "\n",
    "| Amostra | x1 | x2 | x3 | d |\n",
    "|---------|----|----|----|---|\n",
    "| 01 | -0.6508 | 0.1097 | 4.0009 | -1.0000 |\n",
    "| 02 | -1.4492 | 0.8896 | 4.4005 | -1.0000 |\n",
    "| ... | ... | ... | ... | ... |\n",
    "| 29 | 2.0149 | 0.6192 | 10.9263 | -1.0000 |\n",
    "| 30 | 0.2012 | 0.2611 | 5.4631 | 1.0000 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo Haykin, Simon S., em sua obra \"Redes neurais: princípios e prática\", o perceptron opera sob a premissa de que os padrões a ser classificados sejam *linearmente separáveis*. [...] O algoritmo de convergência do perceptron é *não-paramétrico*, significando que ele não faz suposições a respeito da forma das distribuições envolvidas. Ou seja, embora eu não tenha cosiderado em minha resposta anterior a distribuição dos dados, ela faz diferença no perceptron porque ele simplesmente tenta encontrar um hiperplano que separe as classes, independente da distribuição subjacente dos dados. Outra limitação do perceptron de única camada, é que ele faz uma classificação binária entre os dados, esta, sobre a minha perspectiva, é a principal limitação de classificação de padrões do perceptron."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Um sistema de gerenciamento automático de controle de duas válvulas, situado a 500 metros de um processo industrial, envia um sinal codificado constituído de quatro grandezas {x1 , x2 , x3 e x4} que são necessárias para o ajuste de cada uma das válvulas. Conforme mostra a figura abaixo, a mesma via de comunicação é utilizada para acionamento de ambas as válvulas, sendo que o comutador localizado próximo das válvulas deve decidir se o sinal é para a válvula A ou B. Porém, durante a transmissão, os sinais sofrem interferências que alteram o conteúdo das informações transmitidas. Para resolver este problema, treinar-se-á uma rede ADALINE para classificar os sinais ruidosos, que informará ao sistema comutador se os dados devem ser encaminhados para o comando de ajuste da válvula A ou B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('./img/sistema-com-adaline.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[Sistema com Adaline](\"https://github.com/brunocferreira/redes-neurais-artificiais/img/sistema-com-adaline.png\")\n",
    "\n",
    "## Assim, baseado nas medições dos sinais já com ruídos, formou-se o conjunto de treinamento em anexo2 , tomando por convenção o valor –1 para os sinais que devem ser encaminhados para o ajuste da válvula A e o valor +1 se os mesmos devem ser enviados para a válvula B.\n",
    "\n",
    "### Daí, pede-se:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Execute 2 treinamentos para a rede ADALINE inicializando o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def treinamento_adaline(X, y, taxa_aprendizado=0.001, num_iteracoes=10000, tolerancia=1e-3):\n",
    "    \"\"\"\n",
    "    Esta função implementa o algoritmo Adaline (Adaptive Linear Neuron) para treinamento de um modelo linear.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - ``X`` (numpy.ndarray): Matriz de características de entrada.\n",
    "    - ``y`` (numpy.ndarray): Vetor de alvos de saída.\n",
    "    - ``taxa_aprendizado`` (float): Taxa de aprendizado para atualização dos pesos. O padrão é 0.001.\n",
    "    - ``num_iteracoes`` (int): Número de iterações para o treinamento. O padrão é 10000.\n",
    "    - ``tolerancia`` (float): Tolerância para a mudança nos pesos entre as épocas. O padrão é 1e-3.\n",
    "    \n",
    "    Retorno:\n",
    "    - ``peso_`` (numpy.ndarray): Vetor de pesos após o treinamento.\n",
    "    - ``custo_`` (list): Lista do custo em cada iteração.\n",
    "    \n",
    "    Exemplo:\n",
    "    >>> X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "    >>> y = np.array([1, -1, 1])\n",
    "    >>> peso, custo = treinamento_adaline(X, y)\n",
    "    \"\"\"\n",
    "    # Inicializa os pesos de maneira aleatória\n",
    "    peso_ = np.random.rand(1 + X.shape[1])\n",
    "    # Imprime os resultados\n",
    "    print(f'Pesos inicias: {peso_}')\n",
    "    # Inicializa a lista de custos\n",
    "    custo_ = []\n",
    "\n",
    "    # Loop para cada iteração\n",
    "    for i in range(num_iteracoes):\n",
    "        # Guarda os pesos da época anterior\n",
    "        pesos_anteriores = peso_.copy()\n",
    "        # Calcula a saída do modelo\n",
    "        output = np.dot(X, peso_[1:]) + peso_[0]\n",
    "        # Calcula o erro entre a saída desejada e a saída do modelo\n",
    "        erros = (y - output)\n",
    "        # Atualiza os pesos usando a regra de aprendizado do Adaline\n",
    "        peso_[1:] += taxa_aprendizado * X.T.dot(erros)\n",
    "        peso_[0] += taxa_aprendizado * erros.sum()\n",
    "        # Calcula o custo como a soma dos quadrados dos erros\n",
    "        custo = (erros**2).sum() / 2.0\n",
    "        # Armazena o custo para esta iteração\n",
    "        custo_.append(custo)\n",
    "\n",
    "        # Verifica a condição de parada\n",
    "        if np.sqrt(np.sum((peso_ - pesos_anteriores) ** 2)) < tolerancia:\n",
    "            # Imprime os resultados\n",
    "            print(f'O treinamento convergiu após {i+1} épocas.')\n",
    "            print(f'Pesos finais: {peso_}')\n",
    "            print(f'Custo final: {custo_[-1]}')  # Imprime apenas o último custo\n",
    "            return peso_, custo_\n",
    "\n",
    "    # Imprime os resultados se o treinamento não convergiu\n",
    "    print(f'O treinamento não convergiu após {num_iteracoes} épocas.')\n",
    "    print(f'Pesos finais: {peso_}')\n",
    "    print(f'Custo final: {custo_[-1]}')  # Imprime apenas o último custo\n",
    "\n",
    "    # Retorna os pesos finais e a lista de custos\n",
    "    return peso_, custo_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x1      x2      x3      x4    s\n",
      "0  0.4329 -1.3719  0.7022 -0.8535  1.0\n",
      "1  0.3024  0.2286  0.8630  2.7909 -1.0\n",
      "2  0.1349 -0.6445  1.0530  0.5687 -1.0\n",
      "3  0.3374 -1.7163  0.3670 -0.6283 -1.0\n",
      "4  1.1434 -0.0485  0.6637  1.2606  1.0\n",
      "Pesos inicias: [0.16963664 0.33468217 0.09945946 0.21198865 0.58097993]\n",
      "O treinamento convergiu após 1395 épocas.\n",
      "Pesos finais: [-0.11220337  1.45449979  0.06017909 -0.0511775  -1.29866328]\n",
      "Custo final: 10.205914398133196\n",
      "Pesos inicias: [0.46802653 0.87903185 0.12339368 0.2797535  0.90343073]\n",
      "O treinamento convergiu após 1397 épocas.\n",
      "Pesos finais: [-0.11505989  1.47953312 -0.063004   -0.04398938 -1.18395366]\n",
      "Custo final: 10.357904233735137\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Carrega os dados do arquivo .dat para um DataFrame\n",
    "dados2 = pd.read_csv('./data/tab_treinamento2.dat', sep='\\s+', header=None)\n",
    "\n",
    "# Adiciona nomes às colunas\n",
    "dados2.columns = ['x1', 'x2', 'x3', 'x4', 's']\n",
    "\n",
    "# Imprimindo as primeiras linhas do DataFrame\n",
    "print(dados2.head())\n",
    "\n",
    "# Separa as features e os rótulos\n",
    "X2 = dados2.iloc[:, :-1].values\n",
    "y2 = dados2.iloc[:, -1].values\n",
    "\n",
    "# Pré-processamento de dados\n",
    "# Normalização\n",
    "scaler = MinMaxScaler()\n",
    "X2 = scaler.fit_transform(X2)\n",
    "\n",
    "# Divisão de dados\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tratamento de dados ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X2_train = imputer.fit_transform(X2_train)\n",
    "X2_test = imputer.transform(X2_test)\n",
    "\n",
    "# Treina o perceptron\n",
    "peso_1, custo_1 = treinamento_adaline(X2_train, y2_train)\n",
    "peso_2, custo_2 = treinamento_adaline(X2_train, y2_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Registre os resultados dos 2 treinamentos acima na tabela abaixo:\n",
    "\n",
    "| Treinamento | Vetor de Pesos Inicial </br> b \\ w1 \\ w2 \\ w3 \\ w4                 |  Vetor de Pesos Final </br> b \\ w1 \\ w2 \\ w3 \\ w4                                     | Número de Épocas |\n",
    "|-------------|--------------------------------------------------------------------|---------------------------------------------------------------------------------------|------------------|\n",
    "| 1º (T1)     | 0 \\ 0.16963664 \\ 0.33468217 \\ 0.09945946 \\ 0.21198865 \\ 0.58097993 | 10.205914398133196 \\ -0.11220337 \\ 1.45449979 \\ 0.06017909 \\ -0.0511775 \\ -1.29866328 | 1395             |\n",
    "| 2º (T2)     | 0 \\ 0.46802653 \\ 0.87903185 \\ 0.12339368 \\ 0.2797535 \\ 0.90343073  | 10.357904233735137 \\ -0.11505989 \\ 1.47953312 \\ -0.063004 \\ -0.04398938 \\ -1.18395366 | 1397             |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resposta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Para os treinamentos realizados, aplique então a rede ADALINE para classificar e informar ao comutador se os sinais seguintes devem ser encaminhados para a válvula A ou B (ver tab_teste2.dat).\n",
    "\n",
    "| Amostra | x1 | x2 | x3 | x4 | y </br> (T1) |\n",
    "|---------|----|----|----|----|--------------|\n",
    "| 1 |  0.9694 |  0.6909 | 0.4334 | 3.4965 | |\n",
    "| 2 |  0.5427 |  1.3832 | 0.6390 | 4.0352 | |\n",
    "| 3  | 0.6081  | -0.9196 | 0.5925 | 0.1016 |  |\n",
    "| 4  | -0.1618 |  0.4694 | 0.2030 | 3.0117 |  |\n",
    "| 5  | 0.1870  | -0.2578 | 0.6124 | 1.7749 |  |\n",
    "| 6  | 0.4891  | -0.5276 | 0.4378 | 0.6439 |  |\n",
    "| 7 |  0.3777 |  2.0149 | 0.7423 | 3.3932 | |\n",
    "| 8  | 1.1498  | -0.4067 | 0.2469 | 1.5866 |  |\n",
    "| 9 |  0.9325 |  1.0950 | 1.0359 | 3.3591 | |\n",
    "| 10 |  0.5060 |  1.3317 | 0.9222 | 3.7174 |  |\n",
    "| 11 | 0.0497 | -2.0656 | 0.6124 | -0.6585 |  |\n",
    "| 12 |  0.4004 |  3.5369 | 0.9766 | 5.3532 |  |\n",
    "| 13  | -0.1874 |  1.3343 | 0.5374 | 3.2189 | |\n",
    "| 14 |  0.5060 |  1.3317 | 0.9222 | 3.7174 |  |\n",
    "| 15  | 1.6375  | -0.7911 | 0.7537 | 0.5515 | |\n",
    "\n",
    "###### 2 tab_treinamento2.dat\n",
    "\n",
    "#### ANEXO – Conjunto de Treinamento (ver arquivo tab_treinamento2.dat).\n",
    "\n",
    "| Amostra | x1 | x2 | x3 | x4 | d |\n",
    "|---------|----|----|----|----|---|\n",
    "| 01  | 0.4329  | -1.3719 | 0.7022 | -0.8535 |  1.0000 |\n",
    "| 02 |  0.3024 |  0.2286 | 0.8630 | 2.7909  | -1.0000 |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 34 |  0.4662 |  0.6261 | 0.7304 | 3.4370  | -1.0000 |\n",
    "| 35  | 0.8298  | -1.4089 | 0.3119 | 1.3235  | -1.0000 |\n",
    "\n",
    "##### **NOTA**: As questões 3 e 4 foram elaboradas com base em SILVA, I.N. et al..’Redes Neurais Artificiais para Engenharia e Ciências Aplicadas – Fundamentos Teóricos e Práticos.’ Artliber Editora. 2ª Ed. 2016.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adaline(peso, X):\n",
    "    \"\"\"\n",
    "    Esta função usa os pesos do modelo Adaline para fazer previsões em um conjunto de características de entrada.\n",
    "    \n",
    "    Parâmetros:\n",
    "    peso (numpy.ndarray): Vetor de pesos do modelo Adaline.\n",
    "    X (numpy.ndarray): Matriz de características de entrada.\n",
    "    \n",
    "    Retorno:\n",
    "    numpy.ndarray: Vetor de previsões do modelo.\n",
    "    \n",
    "    Exemplo:\n",
    "    >>> X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "    >>> peso = np.array([0.1, 0.2, 0.3])\n",
    "    >>> predicao_adaline(peso, X)\n",
    "    \"\"\"\n",
    "    # Calcula a saída do modelo\n",
    "    output = np.dot(X, peso[1:]) + peso[0]\n",
    "    # Retorna a classe prevista\n",
    "    return np.where(output >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_usando_adaline(pesos):\n",
    "    \"\"\"\n",
    "    Esta função carrega um conjunto de dados do arquivo tab_teste2.dat, realiza o pré-processamento desses dados e faz previsões usando um adaline treinado.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - ``pesos`` (array): O array de pesos do adaline treinado.\n",
    "    \n",
    "    Retorno:\n",
    "    - ``None``. A função imprime os valores preditos para o novo conjunto de dados.\n",
    "    \n",
    "    Exemplo:\n",
    "    >>> prever_novos_dados(peso_1)\n",
    "    Valores preditos, dado os pesos ([0.5, 0.6, 0.7, 0.8]): ['Válvula_1', 'Válvula_2', 'Válvula_1', 'Válvula_2']\n",
    "    \"\"\"\n",
    "    # Carrega os novos dados do arquivo .dat para um DataFrame\n",
    "    dados_novos = pd.read_csv('./data/tab_teste2.dat', sep='\\s+', header=None)\n",
    "\n",
    "    # Adiciona nomes às colunas\n",
    "    dados_novos.columns = ['x1', 'x2', 'x3', 'x4']\n",
    "\n",
    "    # Separa as features\n",
    "    X_novos = dados_novos.values\n",
    "\n",
    "    # Pré-processamento de dados\n",
    "    # Normalização\n",
    "    X_novos = scaler.transform(X_novos)\n",
    "\n",
    "    # Tratamento de dados ausentes\n",
    "    X_novos = imputer.transform(X_novos)\n",
    "\n",
    "    # Faz as previsões com os pesos e vies aprendidos\n",
    "    y_pred = predict_adaline(pesos, X_novos)\n",
    "\n",
    "    # Converte os valores de y_pred para 'C1' se for -1 e 'C2' se for positivo\n",
    "    y_pred = np.where(y_pred == -1, 'Válvula_1', 'Válvula_2')\n",
    "\n",
    "    # Imprime os valores preditos\n",
    "    print(f'Valores preditos, dado os pesos ({pesos}):', y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores preditos, dado os pesos ([-0.11220337  1.45449979  0.06017909 -0.0511775  -1.29866328]): ['Válvula_2' 'Válvula_1' 'Válvula_2' 'Válvula_1' 'Válvula_1' 'Válvula_2'\n",
      " 'Válvula_1' 'Válvula_2' 'Válvula_2' 'Válvula_1' 'Válvula_2' 'Válvula_1'\n",
      " 'Válvula_1' 'Válvula_1' 'Válvula_2']\n",
      "Valores preditos, dado os pesos ([-0.11505989  1.47953312 -0.063004   -0.04398938 -1.18395366]): ['Válvula_2' 'Válvula_1' 'Válvula_2' 'Válvula_1' 'Válvula_1' 'Válvula_2'\n",
      " 'Válvula_1' 'Válvula_2' 'Válvula_2' 'Válvula_1' 'Válvula_2' 'Válvula_1'\n",
      " 'Válvula_1' 'Válvula_1' 'Válvula_2']\n"
     ]
    }
   ],
   "source": [
    "prever_usando_adaline(peso_1)\n",
    "prever_usando_adaline(peso_2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo a predição do adaline treinado, obtivemos o seguinte resultado classificatório para os dados de tab_teste2.dat:\n",
    "\n",
    "| Amostra | x1 | x2 | x3 | x4 | y </br> (T1) | y </br> (T2) |\n",
    "|---------|----|----|----|----|--------------|--------------|\n",
    "| 1 |  0.9694 |  0.6909 | 0.4334 | 3.4965 | Válvula_2 | Válvula_2 |\n",
    "| 2 |  0.5427 |  1.3832 | 0.6390 | 4.0352 | Válvula_1 | Válvula_1 |\n",
    "| 3  | 0.6081  | -0.9196 | 0.5925 | 0.1016 | Válvula_2 | Válvula_2 |\n",
    "| 4  | -0.1618 |  0.4694 | 0.2030 | 3.0117 | Válvula_1 | Válvula_1 |\n",
    "| 5  | 0.1870  | -0.2578 | 0.6124 | 1.7749 | Válvula_1 | Válvula_1 |\n",
    "| 6  | 0.4891  | -0.5276 | 0.4378 | 0.6439 | Válvula_2 | Válvula_2 |\n",
    "| 7 |  0.3777 |  2.0149 | 0.7423 | 3.3932 | Válvula_1 | Válvula_1 |\n",
    "| 8  | 1.1498  | -0.4067 | 0.2469 | 1.5866 | Válvula_2 | Válvula_2 |\n",
    "| 9 |  0.9325 |  1.0950 | 1.0359 | 3.3591 | Válvula_2 | Válvula_2 |\n",
    "| 10 |  0.5060 |  1.3317 | 0.9222 | 3.7174 | Válvula_1 | Válvula_1 |\n",
    "| 11 | 0.0497 | -2.0656 | 0.6124 | -0.6585 | Válvula_2 | Válvula_2 |\n",
    "| 12 |  0.4004 |  3.5369 | 0.9766 | 5.3532 | Válvula_1 | Válvula_1 |\n",
    "| 13  | -0.1874 |  1.3343 | 0.5374 | 3.2189 | Válvula_1 | Válvula_1 |\n",
    "| 14 |  0.5060 |  1.3317 | 0.9222 | 3.7174 | Válvula_1 | Válvula_1 |\n",
    "| 15  | 1.6375  | -0.7911 | 0.7537 | 0.5515 | Válvula_2 | Válvula_2 |\n",
    "\n",
    "###### **Referências**: Válvula_1 -> -1 e Válvula_2 -> +1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Um(a) estudante da disciplina de Redes Neurais e Aprendizado Profundo ficou empolgado(a) com o trabalho do Fisher sobre as flores Íris e resolveu propor uma versão automatizada para ele. Essa nova versão deveria ter dois módulos principais: um módulo de visão computacional e um módulo do tipo classificador neural. Caso você(s) fosse(m) esse(a) estudante, como você(s) desenvolveria(m) esse sistema? Descreva-o em detalhes. Use ilustração(ões) para valorizar o seu pré-projeto. Lembre-se que são três tipos de Íris (Virginica, Versicolor e Setosa) e que 4 parâmetros foram medidos pelo Fisher para cada uma das flores (comprimento e largura da Pétala, Comprimento e largura da Sépala)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O projeto pode ser encontrado no link: [\"Projeto de Sistema Automatizado para Classificação das Flores Íris \"](\"https://docs.google.com/document/d/1oAT9ueBM05FFpA8k3NKCb3u1_8dOVWDOJTld1i-VdRs/edit?usp=sharing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Considere a base de dados encontrada em Irisdat.xlsx.Daí, pede-se:\n",
    "- a) Treinar um PMC que classifique observações de flores íris em 3 espécies (Setosa, Versicolor e Virginica) usando como entradas as características SEPALLENGTH (SL), SEPALWIDTH (SW), PETALLENGTH (PL) e PETALWIDTH (PW).\n",
    "- b) Estime SL a partir de SW, PL, PW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SL</th>\n",
       "      <th>SW</th>\n",
       "      <th>PL</th>\n",
       "      <th>PW</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SETOSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>VIRGINIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>VERSICOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>VIRGINIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>VIRGINIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SL   SW   PL   PW      TYPE\n",
       "0  5.0  3.3  1.4  0.2    SETOSA\n",
       "1  6.4  2.8  5.6  2.2  VIRGINIC\n",
       "2  6.5  2.8  4.6  1.5  VERSICOL\n",
       "3  6.7  3.1  5.6  2.4  VIRGINIC\n",
       "4  6.3  2.8  5.1  1.5  VIRGINIC"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando os dados\n",
    "data = pd.read_excel(\"./data/Irisdat.xlsx\")\n",
    "# Selecionando apenas as colunas desejadas\n",
    "selected_columns = ['SL', 'SW', 'PL', 'PW', 'TYPE']\n",
    "filtered_df = data[selected_columns].dropna()\n",
    "filtered_df = pd.DataFrame(data, columns=['SL', 'SW', 'PL', 'PW', 'TYPE'])\n",
    "for col in ['SL', 'SW', 'PL', 'PW']:\n",
    "    filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce')\n",
    "\n",
    "filtered_df = filtered_df.dropna()\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 39ms/step - loss: 0.8891 - accuracy: 0.5130 - val_loss: 0.8450 - val_accuracy: 0.4828\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8533 - accuracy: 0.4783 - val_loss: 0.8053 - val_accuracy: 0.6207\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8185 - accuracy: 0.6000 - val_loss: 0.7711 - val_accuracy: 0.7586\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7877 - accuracy: 0.6087 - val_loss: 0.7368 - val_accuracy: 0.7586\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7581 - accuracy: 0.6348 - val_loss: 0.7056 - val_accuracy: 0.8276\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7309 - accuracy: 0.6522 - val_loss: 0.6756 - val_accuracy: 0.7931\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7045 - accuracy: 0.6696 - val_loss: 0.6490 - val_accuracy: 0.7931\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6807 - accuracy: 0.6783 - val_loss: 0.6237 - val_accuracy: 0.7931\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6579 - accuracy: 0.6957 - val_loss: 0.5998 - val_accuracy: 0.7931\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.7217 - val_loss: 0.5779 - val_accuracy: 0.7931\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.7304 - val_loss: 0.5571 - val_accuracy: 0.7931\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5965 - accuracy: 0.7391 - val_loss: 0.5379 - val_accuracy: 0.8276\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5787 - accuracy: 0.7565 - val_loss: 0.5198 - val_accuracy: 0.8621\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5615 - accuracy: 0.7739 - val_loss: 0.5028 - val_accuracy: 0.8621\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5454 - accuracy: 0.7826 - val_loss: 0.4863 - val_accuracy: 0.8621\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8000 - val_loss: 0.4711 - val_accuracy: 0.8621\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5160 - accuracy: 0.8000 - val_loss: 0.4569 - val_accuracy: 0.8621\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5029 - accuracy: 0.8087 - val_loss: 0.4418 - val_accuracy: 0.8621\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.8087 - val_loss: 0.4285 - val_accuracy: 0.8621\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4787 - accuracy: 0.8087 - val_loss: 0.4172 - val_accuracy: 0.8966\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4678 - accuracy: 0.8261 - val_loss: 0.4066 - val_accuracy: 0.8966\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4580 - accuracy: 0.8261 - val_loss: 0.3957 - val_accuracy: 0.8966\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.8261 - val_loss: 0.3861 - val_accuracy: 0.8966\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.8261 - val_loss: 0.3765 - val_accuracy: 0.8966\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4312 - accuracy: 0.8261 - val_loss: 0.3677 - val_accuracy: 0.8966\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4243 - accuracy: 0.8000 - val_loss: 0.3596 - val_accuracy: 0.8966\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8174 - val_loss: 0.3522 - val_accuracy: 0.8966\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4100 - accuracy: 0.8087 - val_loss: 0.3446 - val_accuracy: 0.8966\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8261 - val_loss: 0.3386 - val_accuracy: 0.8966\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8348 - val_loss: 0.3325 - val_accuracy: 0.8966\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3923 - accuracy: 0.8348 - val_loss: 0.3279 - val_accuracy: 0.9310\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.8348 - val_loss: 0.3221 - val_accuracy: 0.9310\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3820 - accuracy: 0.8435 - val_loss: 0.3168 - val_accuracy: 0.9310\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3774 - accuracy: 0.8435 - val_loss: 0.3123 - val_accuracy: 0.9655\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8435 - val_loss: 0.3086 - val_accuracy: 0.9655\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3682 - accuracy: 0.8435 - val_loss: 0.3047 - val_accuracy: 0.9655\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.8435 - val_loss: 0.3006 - val_accuracy: 0.9655\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3601 - accuracy: 0.8435 - val_loss: 0.2972 - val_accuracy: 0.9655\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3558 - accuracy: 0.8435 - val_loss: 0.2931 - val_accuracy: 0.9655\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3519 - accuracy: 0.8522 - val_loss: 0.2894 - val_accuracy: 0.9655\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.8522 - val_loss: 0.2861 - val_accuracy: 0.9655\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3449 - accuracy: 0.8522 - val_loss: 0.2822 - val_accuracy: 0.9655\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.8435 - val_loss: 0.2798 - val_accuracy: 0.9655\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3371 - accuracy: 0.8522 - val_loss: 0.2768 - val_accuracy: 0.9655\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3336 - accuracy: 0.8522 - val_loss: 0.2736 - val_accuracy: 0.9655\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3301 - accuracy: 0.8522 - val_loss: 0.2713 - val_accuracy: 0.9655\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.8522 - val_loss: 0.2687 - val_accuracy: 0.9655\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3234 - accuracy: 0.8609 - val_loss: 0.2660 - val_accuracy: 0.9655\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.8609 - val_loss: 0.2634 - val_accuracy: 0.9655\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.8609 - val_loss: 0.2615 - val_accuracy: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x134d3138290>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "# Preparando os dados\n",
    "X = filtered_df[['SL', 'SW', 'PL', 'PW']].values\n",
    "y = filtered_df['TYPE'].values.reshape(-1, 1)\n",
    "\n",
    "# Codificando a saída\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construindo o PMC\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 31ms/step - loss: 29.6218 - val_loss: 31.5182\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.5683 - val_loss: 30.4803\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.5583 - val_loss: 29.4303\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 26.5529 - val_loss: 28.3981\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 25.5437 - val_loss: 27.4086\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.5776 - val_loss: 26.4150\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.6120 - val_loss: 25.4337\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 22.6652 - val_loss: 24.4608\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.7255 - val_loss: 23.5102\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20.8061 - val_loss: 22.5776\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19.9134 - val_loss: 21.6510\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.0129 - val_loss: 20.7716\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.1702 - val_loss: 19.8838\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.3257 - val_loss: 19.0359\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 16.5109 - val_loss: 18.1991\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 15.7213 - val_loss: 17.3742\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 14.9356 - val_loss: 16.5784\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 14.1881 - val_loss: 15.7874\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.4528 - val_loss: 15.0441\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.7558 - val_loss: 14.3062\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.0744 - val_loss: 13.5744\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.3957 - val_loss: 12.8669\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.7499 - val_loss: 12.1879\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.1395 - val_loss: 11.5052\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.5252 - val_loss: 10.8536\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.9401 - val_loss: 10.2273\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.3762 - val_loss: 9.6246\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.8425 - val_loss: 9.0388\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.3266 - val_loss: 8.4840\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.8373 - val_loss: 7.9478\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.3782 - val_loss: 7.4184\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.9206 - val_loss: 6.9215\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.5105 - val_loss: 6.4356\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.1102 - val_loss: 5.9858\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.7250 - val_loss: 5.5812\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.3913 - val_loss: 5.1832\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.0628 - val_loss: 4.8190\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.7754 - val_loss: 4.4714\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.4887 - val_loss: 4.1625\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.2445 - val_loss: 3.8623\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.0203 - val_loss: 3.5830\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.8085 - val_loss: 3.3297\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6238 - val_loss: 3.0941\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.4434 - val_loss: 2.8930\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2947 - val_loss: 2.7060\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.1598 - val_loss: 2.5335\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.0391 - val_loss: 2.3689\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.9268 - val_loss: 2.2239\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.8228 - val_loss: 2.1001\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7389 - val_loss: 1.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x134d3467050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparando os dados de regressão\n",
    "X_reg = filtered_df[['SW', 'PL', 'PW']].values\n",
    "y_reg = filtered_df['SL'].values.reshape(-1, 1)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados de regressão\n",
    "scaler_reg = StandardScaler().fit(X_train_reg)\n",
    "X_train_reg = scaler_reg.transform(X_train_reg)\n",
    "X_test_reg = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "# Construindo o modelo de regressão\n",
    "reg_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(3,)),  # Temos 3 entradas agora: SW, PL, PW\n",
    "    tf.keras.layers.Dense(1)  # A saída é um valor único, SL\n",
    "])\n",
    "\n",
    "# Compilando o modelo de regressão\n",
    "reg_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Treinando o modelo de regressão\n",
    "reg_model.fit(X_train_reg, y_train_reg, epochs=50, batch_size=10, validation_data=(X_test_reg, y_test_reg))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Considere a base de dados encontrada em engines.xlsx, em que ‘Fuel rate’ e ‘Speed’ são variáveis de entrada e ‘Torque’ e ‘Nitrous Oxide Emissions (NOE)’ são as variáveis de saída, respectivamente. Desenvolva três regressores. Um deles deve estimar conjuntamente o ‘Torque’ e o NOE. Já os outros dois devem estimar essas saídas separadamente (i.e. um estimará o Torque e o outro o NOE). Compare o desempenho das duas estratégias apontando qual delas apresenta uma maior capacidade de generalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Loss do regressor conjunto: 0.008158343844115734\n",
      "Loss do regressor torque: 0.00100131391081959\n",
      "Loss do regressor noe: 0.010871821083128452\n"
     ]
    }
   ],
   "source": [
    "#Regressor para estimar conjuntamente o `Torque` e o `NOE``\n",
    "#Regressor para estimar apenas o `Torque`\n",
    "#Regressor para estimar apenas o `NOE`\n",
    "#Comparação\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Carregando e transpondo os dados\n",
    "data_engine = pd.read_excel(\"./data/engines-tratado.xlsx\")\n",
    "\n",
    "# Preparação dos dados\n",
    "X = data_engine[['fuel_rate', 'speed']]\n",
    "y = data_engine[['torque', 'noe']]\n",
    "\n",
    "# Divisão dos dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "X_train = scaler_X.transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler().fit(y_train)\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "# Construindo o regressor conjunto\n",
    "model_conjunto = Sequential([\n",
    "    Dense(32, activation='relu', input_dim=2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='linear')  # Duas saídas: torque e noe\n",
    "])\n",
    "model_conjunto.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Treinamento do regressor conjunto\n",
    "model_conjunto.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Avaliação do regressor conjunto\n",
    "loss_conjunto = model_conjunto.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Construindo e treinando regressores individuais\n",
    "outputs = ['torque', 'noe']\n",
    "losses = {}\n",
    "for output in outputs:\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_dim=2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    y_train_single = y_train[:, outputs.index(output)]\n",
    "    y_test_single = y_test[:, outputs.index(output)]\n",
    "    model.fit(X_train, y_train_single, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    losses[output] = model.evaluate(X_test, y_test_single, verbose=1)\n",
    "\n",
    "# Comparando o desempenho\n",
    "print(f\"Loss do regressor conjunto: {loss_conjunto}\")\n",
    "for output, loss in losses.items():\n",
    "    print(f\"Loss do regressor {output}: {loss}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Loss do regressor conjunto: 0.008158343844115734** \n",
    "   \n",
    "   Este valor refere-se à perda de um modelo que tenta prever ambas as saídas (\"Torque\" e \"NOE\") simultaneamente. O valor é relativamente baixo, mas para avaliar se é realmente bom, é preciso comparar com uma baseline ou benchmark adequado.\n",
    "\n",
    "2. **Loss do regressor torque: 0.00100131391081959** \n",
    "   \n",
    "   Este valor é significativamente menor do que o regressor conjunto, indicando que este modelo específico que prevê somente o \"Torque\" é mais preciso (ou tem menos erro) do que o regressor conjunto, pelo menos no que diz respeito à variável \"Torque\".\n",
    "\n",
    "3. **Loss do regressor noe: 0.010871821083128452** \n",
    "   \n",
    "   Este valor é o mais alto entre os três. Indica que o modelo que prevê somente \"NOE\" tem o maior erro entre os modelos apresentados. É quase 2,3 vezes maior do que o erro do regressor conjunto e muito maior do que o erro do regressor de torque.\n",
    "\n",
    "Em resumo:\n",
    "\n",
    "- O modelo para \"Torque\" parece ser o mais preciso.\n",
    "- O modelo para \"NOE\" parece ser o menos preciso.\n",
    "- O modelo conjunto, que tenta prever ambas as saídas simultaneamente, fica entre os dois em termos de precisão."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Valendo-se da base de dados reais referente ao Volume de Vendas de Passagens (VVP) de uma companhia aérea norte-americana que se encontra no arquivo vvp.xlsx, pede-se:\n",
    "- 1) Desenvolver um previsor neural que receba como entradas os VVPs registrados nos instantes k-1 e k-12 (i.e. VVP(k-1) e VVP(k-12)) e que disponibilize na saída o VVP no instante corrente k (i.e. VVP(k)). O previsor deverá realizar previsões recursivas de 1 a 12 passos à frente (i.e., de um a doze meses à frente);\n",
    "- 2) De posse da base de dados, remova a tendência linear presente na base de dados original. Desse modo, você conhecerá a série destendenciada e a tendência linear. Para a primeira série, desenvolva um previsor neural que receba como entradas os VVPs registrados nos instantes k-1 e k-12 (i.e. VVP(k-1) e VVP(k-12)) e que disponibilize na saída o VVP no instante corrente k (i.e. VVP(k)). O previsor deverá realizar previsões recursivas de 1 a 12 passos à frente (i.e., de um a doze meses à frente). Para a segunda (i.e., a tendência linear), preveja linearmente os próximos dozes pontos. Em seguida, some ponto a ponto as duas previsões e compare o desempenho dessa abordagem com a anterior apontando qual delas apresenta uma maior capacidade de generalização."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resposta..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Procure na literatura 2 artigos que tratem do tema Sensores Inferenciais (ou Soft Sensors) para uma dada grandeza de seu interesse (e.g. temperatura, pressão, vazão, nível etc.) e que tenham sido publicados nos últimos 5 anos. Explique de forma sucinta o que foi desenvolvido pelos autores, referenciando-os. **Sugestão**: As principais informações de qualquer artigo geralmente se encontram no título, no resumo e nas conclusões. Ao ler esses três itens, o leitor tem uma boa ideia do que esperar daquele trabalho. A propósito, usualmente o leitor decidirá se lerá todo o artigo ou não com base na sua impressão a respeito desses três itens."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grandeza escolhida foi temperatura, por ser extremamente difícil de realizar sua predição em situações adversas. Para tais situação, selecionamos os seguintes artigos:\n",
    "- *XU, Feng et al*. **Soft-Sensor Modeling of Temperature Variation in a Room under Cooling Conditions**. Energies, 2023. [\"DOI 10.3390/en16062870\"](\"https://doi.org/10.3390/en16062870\").\n",
    "- *DUAN, Yanhui et al*. **A Dynamic Time Warping Based Locally Weighted LSTM Modeling for Temperature Prediction of Recycled Aluminum Smelting**. IEEE Access, 2023 [\"DOI 10.1109/ACCESS.2023.3266518\"](\"https://ieeexplore-ieee-org.ez359.periodicos.capes.gov.br/document/10100736\")."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro, trabalho do XU et al., da modelagem de um sensor inferencial da medição de temperatura em uma sala sob condições de resfriamento, conseguiram um resultado muito bom em que o modelo de cada local alvo - que foram diversos nos aparelhos de utilizados para aquecer, resfriar e ventilar o ar do ambiente; demonstraram uma boa precisão, com os valores de Erro Absoluto Médio (MAE) dentro de 0,69 Kelvin para várias temperaturas iniciais (de 25 a 35 °C) e de vazão inicial (de 770 a 850 mL/min). O resultado do modelo do sensor inferencial foi desenvolvido utilizando o médo de regressão linear múltipla, após XU et al. analisarem outros trabalhos semelhantes em que utilizam redes neurais artificials, aprendizagem profunda e modelos de regressão linear, que estes estudos incorporam menos mecanismos de processo na construção e análise de modelos de sensores inferenciais usados em áreas de ar condicionado. Entretanto, apesar do modelo prever com precisão as temperaturas locais mantendo uma gestão eficiente da energia e do conforto, também no resfiamento do ambiente, XU et al ressalta avaliar o desempenho do modelo do sensor inferencial de temperatura para os modos de aquecimento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já no segundo, trabalho do DUAN et al., cujo a complexidade está inclusa desde o título ao propor um modelo para medir a similaridade entre duas sequências temporais - que podem ter velocidade assíncrona; através de uma rede neural recorrente LSTM, capaz de aprender com o tempo, e ponderada para prever a temperatura em um processo de alumínio reciclado. Para eles lidarem com os problemas na previsão da temperatura do forno de um forno de fundição de alumínio regenerativo, é proposto um método de modelagem de sensor suave baseado em DFC-DLWLSTM. Este método de modelagem extrai completamente as características temporais dos dados usando redes neurais LSTM. Eles definiram isso ao perceberem pela literatura que as redes neurais artificiais (ANN) são promissoras para a modelagem de sensores inferenciais para uma estrutura estática. Entretanto, se utilizassem uma rede neural recorrente (RNN) sanaria a questão se não fosse pelo fato dela ser sensível a explosão ou ausência de gradiente ao lidar com série temporais, daí a escolha da rede neural de memória de longo prazo (LSTM). Isso tudo para selecionar para o como base para o trabalho um modelo LSTM ponderado para a distorção de tempo dinâmico (DTW) e propor um modelo de classificação de condição de operação e previsão composto por um algoritmo de *c-means difuso* (FCM) baseando em distorção de tempo dinâmico (DTW) e rede neural convolucional (CNN) que é denotado como DFC. Daí o modelo **DFC-DLWLSTM**. O modelo local para as amostras de consulta é construído considerando os pesos de diferentes amostras de entrada históricas. Isso não só resolve o problema da variação de tempo, mas também extrai efetivamente as características não lineares das amostras de entrada. O modelo proposto por DUAN et al. foi testado usando dados reais de uma planta de fundição de alumínio e os resultados mostraram que ele funciona bem, confirmando assim a validade do método proposto. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53dd1628369cdd05e878fd6485b388de34e4a7c0330a8f2d09275b55a4f840cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
